{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4-XJ9EY8Awq"
      },
      "source": [
        "# ID2214/FID3214 Assignment 2 Group no. ID2214 - 5\n",
        "### Project members:\n",
        "\n",
        "Lukas Olenborg,\n",
        "Charlotte Jacquet,\n",
        "Isabella Rositi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeC38hkU8Awt"
      },
      "source": [
        "## Load NumPy, pandas and time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9H38hU28azL",
        "outputId": "a8dd24f2-a23c-4377-e7d8-f3c940765f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdFmkpLj8giL"
      },
      "outputs": [],
      "source": [
        "# Filepath to shared drive (you have to add the 'Programming for Data Science' folder to your drive)\n",
        "filepath = '/content/drive/MyDrive/Programming for Data Science/Assignment 2/'\n",
        "\n",
        "# Filepath to your own drive folder and files if above doesnt work\n",
        "#filepath = '/content/drive/MyDrive/Colab Notebooks/ID2214/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filepath for TA, uncomment when submitting\n",
        "#filepath = ''"
      ],
      "metadata": {
        "id": "HigSZv2rkYfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxUIh4Xa8Awt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math as mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPWQsJ5_8Awu",
        "outputId": "c0f53f29-ba3e-4dbb-e5c1-93c62bb47e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.8.15\n",
            "NumPy version: 1.21.6\n",
            "Pandas version: 1.3.5\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "\n",
        "print(f\"Python version: {python_version()}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzZWP5TG8Awv"
      },
      "source": [
        "## Reused functions from Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV9mNjrz8Awv"
      },
      "outputs": [],
      "source": [
        "# Copy and paste functions from Assignment 1 here that you need for this assignment\n",
        "\n",
        "# FILTERING\n",
        "def create_column_filter(df):\n",
        "\n",
        "    # copy the input dataframe into df_copy\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    for colname, values in df.iteritems():\n",
        "        # only do something if it's not labeled 'CLASS' or 'ID'\n",
        "        if colname == \"CLASS\" or colname == \"ID\":\n",
        "          continue\n",
        "        else:\n",
        "            # Drop a column if it contains only missing values\n",
        "            df_copy = df_copy.dropna(how = 'all', axis=1)\n",
        "\n",
        "            # Drop a column if there's only one unique value...\n",
        "            arr = df[colname].unique()\n",
        "            # ... apart from the missing values\n",
        "            arr = arr[~ pd.isnull(arr)] # '~' = np not operator (!), isnull = True where nan\n",
        "            if arr.size == 1:\n",
        "                #if colname in df_copy.columns: # this line replaced with errors='ignore' below\n",
        "                df_copy = df_copy.drop([colname], axis=1, errors='ignore')\n",
        "            #alternative apart from the missing values\n",
        "            # elif arr.size == 2:\n",
        "            #   for i in range(arr.size):\n",
        "            #       if np.isnan(arr[i]):\n",
        "            #           df_copy = df_copy.drop([colname],axis=1, errors='ignore')\n",
        "\n",
        "\n",
        "    column_filter = df_copy.columns.values.tolist()\n",
        "\n",
        "    return df_copy, column_filter\n",
        "\n",
        "def apply_column_filter(df, column_filter):\n",
        "    return df.loc[:,column_filter] # : for all rows , column_filter cols\n",
        "\n",
        "\n",
        "#IMPUTATION\n",
        "def create_imputation(df):\n",
        "    dfcpy = df.copy()\n",
        "    imputation = {}\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col == \"ID\" or col == \"CLASS\":\n",
        "            continue\n",
        "\n",
        "        coltype = dfcpy[col].dtypes # get type of column\n",
        "\n",
        "        if coltype == \"int64\" or coltype == \"float64\":\n",
        "            # Replace nan values with mean of column for numeric cols\n",
        "            mean = np.mean(dfcpy[col])\n",
        "\n",
        "            # Rare case - all values nan\n",
        "            if np.isnan(mean):\n",
        "                mean = 0\n",
        "\n",
        "            dfcpy[col] = dfcpy[col].fillna(mean)\n",
        "            imputation[col] = mean\n",
        "\n",
        "        if coltype == \"object\" or coltype == \"category\":\n",
        "            # Replace nan values with mode (most common value) for object/catg columns\n",
        "            mode = dfcpy[col].mode()\n",
        "\n",
        "            # Rare case - all values nan (the category one in Hint 4 doesnt make sense\n",
        "            # since category[0] = nan ...)\n",
        "            if mode.empty:\n",
        "                mode = \"\"\n",
        "            else:\n",
        "                mode = mode[0]\n",
        "\n",
        "            dfcpy[col] = dfcpy[col].fillna(mode)\n",
        "            imputation[col] = mode\n",
        "\n",
        "    return dfcpy, imputation\n",
        "\n",
        "def apply_imputation(df, imputation):\n",
        "    dfcpy = df.copy()\n",
        "    for col in df.columns:\n",
        "        if col == \"CLASS\" or col == \"ID\":\n",
        "            continue\n",
        "\n",
        "        # Check if this col was imputed\n",
        "        if col in imputation:\n",
        "            value = imputation[col] # get imputation (mean or mode)\n",
        "            dfcpy[col] = dfcpy[col].fillna(value)\n",
        "\n",
        "    return dfcpy\n",
        "\n",
        "\n",
        "\n",
        "#NORMALIZATION\n",
        "def create_normalization(df, normalizationtype='minmax'):\n",
        "    # copy the input dataframe into df_copy\n",
        "    df_copy = df.copy()\n",
        "    mapping = {}\n",
        "    for colname, values in df_copy.iteritems():\n",
        "\n",
        "        # only do something if it's not labeled 'CLASS' or 'ID'\n",
        "        if colname == \"CLASS\" or colname == \"ID\":\n",
        "          continue\n",
        "        else :\n",
        "            # Consider column of type \"float\" or \"int\"\n",
        "            # Normalization of the value\n",
        "            if df_copy[colname].dtype == 'float64' or 'int32' or 'int64' or 'float32':\n",
        "                # dictionary from each column name to a triple (\"minmax\",min_value,max_value) or (\"zscore\",mean,std)\n",
        "\n",
        "                if normalizationtype == \"zscore\":\n",
        "                    # z normalization\n",
        "                    mean = df_copy[colname].mean()\n",
        "                    std = df_copy[colname].std()\n",
        "                    #apply z normalization\n",
        "                    df_copy[colname] = df_copy[colname].apply(lambda x: (x-mean)/std)\n",
        "                    #filling the dictionary\n",
        "                    triple = [\"zscore\", mean, std]\n",
        "                    mapping[colname] = triple\n",
        "\n",
        "\n",
        "                else :\n",
        "                    #min-max normalization\n",
        "                    min = df_copy[colname].min()\n",
        "                    max = df_copy[colname].max()\n",
        "                    # apply min-max normalization\n",
        "                    df_copy[colname] = [(x-min)/(max-min) for x in df_copy[colname]]\n",
        "                    # store max,mean and mean for each column\n",
        "                    # for each column dictionary with three values (nested dictionary)\n",
        "                    triple = [\"minmax\", min, max]\n",
        "                    mapping[colname] = triple\n",
        "\n",
        "    #print(df_copy)\n",
        "\n",
        "    return df_copy, mapping\n",
        "\n",
        "def apply_normalization(df, mapping):\n",
        "    # copy the input dataframe into df_copy\n",
        "    df_copy = df.copy()\n",
        "    for colname, values in df_copy.iteritems():\n",
        "\n",
        "        # only do something if it's not labeled 'CLASS' or 'ID'\n",
        "        if colname == \"CLASS\" or colname == \"ID\":\n",
        "          continue;\n",
        "        else :\n",
        "            # Consider column of type \"float\" or \"int\"\n",
        "            # Normalization of the value\n",
        "            if df_copy[colname].dtype == 'float64' or 'int32' or 'int64' or 'float32':\n",
        "\n",
        "                if mapping.get(colname)[0] == 'zscore':\n",
        "                    # z normalization\n",
        "                    mean = mapping[colname][1]\n",
        "                    std = mapping[colname][2]\n",
        "                    #apply z normalization\n",
        "                    df_copy[colname] = df_copy[colname].apply(lambda x: (x-mean)/std)\n",
        "\n",
        "                else :\n",
        "                    #min-max normalization\n",
        "                    min = mapping[colname][1]\n",
        "                    max = mapping[colname][2]\n",
        "\n",
        "\n",
        "                    # apply min-max normalization\n",
        "                    # limit the output range to [0,1]\n",
        "\n",
        "                    df_copy[colname] = [1 if (x-min)/(max-min) > 1 else 0 if (x-min)/(max-min) < 0 else (x-min)/(max-min) for x in df_copy[colname]]\n",
        "\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "#ONE-HOT\n",
        "def create_one_hot(df):\n",
        "    # copy the input dataframe into df_copy and create an empy dictionary\n",
        "    df_copy = df.copy()\n",
        "    one_hot = {}\n",
        "    # only do something if the column is not labeled 'CLASS' or 'ID'\n",
        "    for colname, values in df_copy.iteritems():\n",
        "        if colname == \"CLASS\" or colname == \"ID\":\n",
        "            continue\n",
        "        else :\n",
        "            # consider column of type \"object\" or \"category\"\n",
        "            if df_copy[colname].dtype == 'category':\n",
        "                # get the values and put them in the dictionary\n",
        "                one_hot[colname] = df_copy[colname].unique()\n",
        "                # create new columns with the one_hot encoding\n",
        "                for i, val in enumerate(values):\n",
        "                    # ADDED str() below due to new error (val == float64)\n",
        "                    df_copy[colname+\"_\"+str(val)] = df_copy[colname].apply(lambda x: 1 if x==val else 0)\n",
        "                # drop the old column\n",
        "                df_copy.drop(colname, axis=1, inplace=True)\n",
        "    return df_copy, one_hot\n",
        "\n",
        "def apply_one_hot(df, one_hot):\n",
        "    # copy the input dataframe into df_copy\n",
        "    df_copy = df.copy()\n",
        "    for colname, values in df_copy.iteritems():\n",
        "        for key, val in list(one_hot.items()):\n",
        "            # only do something if the column is already in the dictionary\n",
        "            if colname == key:\n",
        "                #create new columns with the one_hot encoding\n",
        "                for i, v in enumerate(val):\n",
        "                    df_copy[key+\"_\"+v] = df_copy[key].apply(lambda x: 1 if x==v else 0)\n",
        "                #drop the old column\n",
        "                df_copy.drop(key, axis=1, inplace=True)\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "\n",
        "#ACCURACY\n",
        "def accuracy(df,correctlabels):\n",
        "\n",
        "    preds = df.idxmax(axis=1) # get index(col) of max value on axis=1(row-wise)\n",
        "    # print(correctlabels)\n",
        "    # print(type(correctlabels))\n",
        "\n",
        "    # print()\n",
        "    # print(preds)\n",
        "    # print(type(preds))\n",
        "\n",
        "    correct = np.sum(preds == correctlabels) # get nr of equal values in two arrays\n",
        "\n",
        "    acc = correct/len(correctlabels)\n",
        "\n",
        "    return acc\n",
        "\n",
        "\n",
        "\n",
        "#BRIER SCORE\n",
        "def brier_score(df, correctlabels):\n",
        "    #create matrix of zeros for true classes\n",
        "    t_class = np.zeros((len(df), len(np.unique(correctlabels))))\n",
        "    for colname, values in df.iteritems():\n",
        "        #get the index of the true class\n",
        "        ind = np.where(df.columns==colname)[0]\n",
        "        for i, v in enumerate(correctlabels):\n",
        "            # find the true class and change the values from 0 to 1\n",
        "            if v == colname:\n",
        "                t_class[i][ind] = 1\n",
        "    # brier_score\n",
        "    brier = np.mean(np.sum((df - t_class)**2, axis=1))\n",
        "    return brier\n",
        "\n",
        "# BINNING\n",
        "def create_bins(df, nobins = 10, bintype=\"equal-width\"):\n",
        "    # copy the input dataframe into df_copy and create an empty dictionary\n",
        "    df_copy = df.copy()\n",
        "    binning = {}\n",
        "    # only do something if the column is not labeled 'CLASS' or 'ID'\n",
        "    for colname, values in df_copy.iteritems():\n",
        "        if colname == \"CLASS\" or colname == \"ID\":\n",
        "            continue;\n",
        "        else :\n",
        "            # only consider column of type \"float\" or \"int\"\n",
        "            if df_copy[colname].dtype == 'float64' or 'int32' or 'int64' or 'float32':\n",
        "                # create the categories for each value and the tresholds for the bins\n",
        "                if bintype == \"equal-width\":\n",
        "                    cat = pd.cut(df_copy[colname], bins=nobins, labels=False, retbins = True, duplicates = \"drop\")\n",
        "                elif bintype == \"equal-size\":\n",
        "                    cat = pd.qcut(df_copy[colname], q=nobins, labels=False, retbins = True, duplicates = \"drop\")\n",
        "                # replace with the categories and change column type to \"category\"\n",
        "                df_copy[colname] = cat[0].astype('category')\n",
        "                # change the first and the last element of each binning to -np.inf and np.inf\n",
        "                cat[1][0] = -np.inf\n",
        "                cat[1][-1] = np.inf\n",
        "                # add to dictionary\n",
        "                binning[colname] = cat[1]\n",
        "    return df_copy, binning\n",
        "\n",
        "\n",
        "\n",
        "def apply_bins(df, binning):\n",
        "    # copy the input dataframe into df_copy\n",
        "    df_copy = df.copy()\n",
        "    for colname, values in df_copy.iteritems():\n",
        "       # only do something if the column is already in the dictionary\n",
        "       for key, value in list(binning.items()):\n",
        "            if colname == key:\n",
        "                # create the category based on the bins provided in binning\n",
        "                cat = pd.cut(df_copy[colname], bins=binning[colname], labels=False, retbins = False, duplicates = \"drop\")\n",
        "                # replace with the categories and change type to \"category\"\n",
        "                df_copy[colname] = cat.astype('category')\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "#AUC\n",
        "def auc(df,correctlabels):\n",
        "    all_dicts = []\n",
        "\n",
        "    # Create triple dictionaries for each class\n",
        "    for col in df.columns:\n",
        "\n",
        "        # Initialize dictionary with s_i --> [0,0]\n",
        "        triples = {}\n",
        "        for prob in df[col]:\n",
        "            triples[prob] = [0,0]\n",
        "\n",
        "        # Generate dictionary\n",
        "        i = 0\n",
        "        for prob in df[col]:\n",
        "            # number of istances in that class\n",
        "            if correctlabels[i] == col:\n",
        "                triples[prob][0] += 1\n",
        "            # number of istances not in that class\n",
        "            else:\n",
        "                triples[prob][1] += 1\n",
        "            i+=1\n",
        "\n",
        "        # print(f\"Triples for {col}:\")\n",
        "        # print(triples)\n",
        "        # print()\n",
        "        all_dicts.append(triples)\n",
        "\n",
        "    AUCs = [] # list for all AUCs\n",
        "\n",
        "    # Calculate AUC for each triple dictionary\n",
        "    for dicts in all_dicts:\n",
        "\n",
        "        # Calculate total tps and fps\n",
        "        tot_tp = 0\n",
        "        tot_fp = 0\n",
        "        # print(\"Probability ordering:\")\n",
        "        for prob in sorted(dicts,reverse=True):\n",
        "            # print(prob)\n",
        "            pair = dicts[prob]\n",
        "            tot_tp += pair[0]\n",
        "            tot_fp += pair[1]\n",
        "        # print()\n",
        "\n",
        "        # Begin AUC algorithm\n",
        "        single_AUC = 0\n",
        "        cov_tp = 0\n",
        "\n",
        "        # Loop through the sorted pairs\n",
        "        for prob in sorted(dicts,reverse=True):\n",
        "            pair = dicts[prob]\n",
        "            tp = pair[0]\n",
        "            fp = pair[1]\n",
        "\n",
        "            if fp == 0:\n",
        "                cov_tp += tp\n",
        "            elif tp == 0:\n",
        "                single_AUC += (cov_tp/tot_tp) * (fp/tot_fp)\n",
        "            else:\n",
        "                single_AUC += (cov_tp/tot_tp) * (fp/tot_fp) + ((tp/tot_tp) * (fp/tot_fp))/2\n",
        "                cov_tp += tp\n",
        "\n",
        "        AUCs.append(single_AUC)\n",
        "\n",
        "    # print(\"All AUCs:\")\n",
        "    # print(AUCs)\n",
        "    # print()\n",
        "\n",
        "    # Count how many times each col appears in correct labels\n",
        "    col_correct = []\n",
        "    for col in df.columns:\n",
        "        correct_count = 0\n",
        "        for label in correctlabels:\n",
        "            if col == label:\n",
        "                correct_count += 1\n",
        "        # print(f\"{col} is correct {correct_count} times\")\n",
        "        col_correct.append(correct_count)\n",
        "\n",
        "    # Compute final weighted AUC\n",
        "    AUC = 0\n",
        "    for i in range(len(AUCs)):\n",
        "        weight = col_correct[i]/len(correctlabels)\n",
        "        AUC += weight * AUCs[i]\n",
        "\n",
        "    # print()\n",
        "    return AUC\n",
        "\n",
        "\n",
        "#EUCLIDEAN DISTANCE\n",
        "def eucledian(p1,p2):\n",
        "    dist = np.sqrt(np.sum((p1-p2)**2))\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRMSouUX8Awv"
      },
      "source": [
        "## 1. Define the class kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTfIu85s8Awv"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "# Define the class kNN with three functions __init__, fit and predict (after the comments):\n",
        "class kNN:\n",
        "\n",
        "# Input to __init__:\n",
        "# self - the object itself\n",
        "#\n",
        "# Output from __init__:\n",
        "# <nothing>\n",
        "#\n",
        "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
        "# column_filter, imputation, normalization, one_hot, labels, training_labels, training_data, training_time\n",
        "    def __init__(self):\n",
        "        self.column_filter = None\n",
        "        self.imputation = None\n",
        "        self.normalization = None\n",
        "        self.one_hot = None\n",
        "        self.labels = None\n",
        "        self.training_labels = None\n",
        "        self.training_data = None\n",
        "        self.training_time = None\n",
        "\n",
        "# Input to fit:\n",
        "# self              - the object itself\n",
        "# df                - a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
        "# normalizationtype - \"minmax\" (default) or \"zscore\"\n",
        "#\n",
        "# Output from fit:\n",
        "# <nothing>\n",
        "#\n",
        "# The result of applying this function should be:\n",
        "#\n",
        "# self.column_filter   - a column filter (see Assignment 1) from df\n",
        "# self.imputation      - an imputation mapping (see Assignment 1) from df\n",
        "# self.normalization   - a normalization mapping (see Assignment 1), using normalizationtype from the imputed df\n",
        "# self.one_hot         - a one-hot mapping (see Assignment 1)\n",
        "# self.training_labels - a pandas series corresponding to the \"CLASS\" column, set to be of type \"category\"\n",
        "# self.labels          - a list of the categories (class labels) of the previous series\n",
        "# self.training_data   - the values (an ndarray) of the transformed dataframe, i.e., after employing imputation,\n",
        "#                        normalization, and possibly one-hot encoding, and also after removing the \"CLASS\" and \"ID\" columns\n",
        "#\n",
        "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
        "    def fit(self, df, normalizationtype='minmax'):\n",
        "        dfcpy = df.copy()\n",
        "\n",
        "        # df_flitered : new df where columns containing only missing values have been dropped\n",
        "        # col_filter : list of the names of the remaining columns\n",
        "        df_filtered, col_filter = create_column_filter(dfcpy)\n",
        "        self.column_filter = col_filter\n",
        "\n",
        "        # df_imputed : new df missing numeric value in a column has been replaced by the mean of that column\n",
        "        # missing categoric value in a column has been replaced by the mode of that column imputation\n",
        "        # impt: mapping (dictionary) from column name to value that has replaced missing values\n",
        "        df_imputed, impt = create_imputation(df_filtered)\n",
        "        self.imputation = impt\n",
        "\n",
        "        # df_normalized: new df where numeric value in a column has been replaced by a normalized value\n",
        "        # mapping: dictionary from each column name to a triple, consisting of\n",
        "        # (\"minmax\",min_value,max_value) or (\"zscore\",mean,std)\n",
        "        df_normalized, mapping = create_normalization(df_imputed,'minmax')\n",
        "        self.normalization = mapping\n",
        "\n",
        "        #df_onehot: new df where each categoric feature has been replaced by a set of binary features\n",
        "        # one_hot: dictionary from column name to a set of categories (possible values for the feature)\n",
        "        # is the hot encoding right because also numerical values are here encoded?\n",
        "        df_onehot, one_h = create_one_hot(df_normalized)\n",
        "        self.one_hot = one_h\n",
        "\n",
        "        #get a series of the column \"CLASS\" and make it of catgeory type\n",
        "        categories = dfcpy['CLASS'].astype('category')\n",
        "        self.training_labels = categories\n",
        "\n",
        "        # list of class labels\n",
        "        self.classes = sorted(dfcpy[\"CLASS\"].unique())\n",
        "\n",
        "        #the values (an ndarray) of the transformed dataframe, i.e., after employing imputation,\n",
        "        #normalization, and possibly one-hot encoding, and also after removing the \"CLASS\" and \"ID\" columns\n",
        "        data = df_onehot.drop(['CLASS', 'ID'], axis=1)\n",
        "        self.training_data = data.values\n",
        "\n",
        "\n",
        "# Input to predict:\n",
        "# self - the object itself\n",
        "# df   - a dataframe\n",
        "# k    - an integer >= 1 (default = 5)\n",
        "#\n",
        "# Output from predict:\n",
        "# predictions - a dataframe with class labels as column names and the rows corresponding to\n",
        "#               predictions with estimated class probabilities for each row in df, where the class probabilities\n",
        "#               are estimated by the relative class frequencies in the set of class labels from the k nearest\n",
        "#               (with respect to Euclidean distance) neighbors in training_data\n",
        "#\n",
        "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply column filtering, imputation, normalization and one-hot\n",
        "#\n",
        "# Hint 2: Get the numerical values (as an ndarray) from the resulting dataframe and iterate over the rows\n",
        "#         calling some sub-function, e.g., get_nearest_neighbor_predictions(x_test,k), which for a test row\n",
        "#         (numerical input feature values) finds the k nearest neighbors and calculate the class probabilities.\n",
        "#\n",
        "# Hint 3: This sub-function may first find the distances to all training instances, e.g., pairs consisting of\n",
        "#         training instance index and distance, and then sort them according to distance, and then (using the indexes\n",
        "#         of the k closest instances) find the corresponding labels and calculate the relative class frequencies\n",
        "\n",
        "\n",
        "    def get_nearest_neighbor_predictions(self, x_test, k):\n",
        "\n",
        "        #create list for labels for each data point in test set\n",
        "        op_labels = []\n",
        "        probs = np.zeros((len(x_test), len(self.classes)))\n",
        "\n",
        "        #loop through each test data\n",
        "\n",
        "        for item in x_test:\n",
        "            #Array to store distances\n",
        "            point_dist = []\n",
        "\n",
        "            #Loop through each training Data\n",
        "            for j in range(len(self.training_data)):\n",
        "                #Calculating the distance between each item of the test set and each row of the train set\n",
        "                distances = eucledian(item, np.array(self.training_data[j,:]))\n",
        "                point_dist.append(distances)\n",
        "            point_dist = np.array(point_dist)\n",
        "\n",
        "            #Sorting the array while preserving the index and keeping only the first K datapoints\n",
        "            dist = np.argsort(point_dist)[:k]\n",
        "\n",
        "            labels = []\n",
        "            #get the class of the k datapoints\n",
        "            for d in dist:\n",
        "                labels.append(self.training_labels[d])\n",
        "            op_labels.append(labels)\n",
        "\n",
        "\n",
        "        for i in range(len(x_test)):\n",
        "            for d in range(k):\n",
        "                for c in range(len(self.classes)):\n",
        "                    if op_labels[i][d] == self.classes[c]:\n",
        "                        probs[i][c] += 1\n",
        "\n",
        "        df_probs = pd.DataFrame(probs, columns= self.classes)\n",
        "        for col, val in df_probs.iteritems():\n",
        "            df_probs[col] = df_probs[col].apply(lambda x: x/k)\n",
        "\n",
        "        return df_probs\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, df, k):\n",
        "        dfcpy = df.copy()\n",
        "\n",
        "        #apply the filters created in the fit function\n",
        "        df_filtered = apply_column_filter(dfcpy,self.column_filter)\n",
        "        df_imputed = apply_imputation(df_filtered, self.imputation)\n",
        "        df_normalized = apply_normalization(df_imputed, self.normalization)\n",
        "        df_onehot = apply_one_hot(df_normalized, self.one_hot)\n",
        "        df_onehot = df_onehot.drop(['CLASS','ID'], axis=1)\n",
        "        self.test_data = df_onehot.values\n",
        "\n",
        "        predictions = self.get_nearest_neighbor_predictions(self.test_data, k)\n",
        "\n",
        "        #print(\"Predictions\")\n",
        "        #print(predictions)\n",
        "        #print()\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "cA5U2z_B8Aww",
        "outputId": "10dcf61d-a36a-4c16-a545-777244fbb2cb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.03 s.\n",
            "Testing time (k=1): 0.18 s.\n",
            "Testing time (k=3): 0.15 s.\n",
            "Testing time (k=5): 0.14 s.\n",
            "Testing time (k=7): 0.16 s.\n",
            "Testing time (k=9): 0.16 s.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'results'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Accuracy  Brier score       AUC\n",
              "1  0.747664     0.504673  0.810350\n",
              "3  0.663551     0.488058  0.815859\n",
              "5  0.579439     0.471028  0.833843\n",
              "7  0.598131     0.471867  0.833481\n",
              "9  0.616822     0.482981  0.827727"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83362be8-2c02-4abe-9313-d5b70701481b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Brier score</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747664</td>\n",
              "      <td>0.504673</td>\n",
              "      <td>0.810350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.663551</td>\n",
              "      <td>0.488058</td>\n",
              "      <td>0.815859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.579439</td>\n",
              "      <td>0.471028</td>\n",
              "      <td>0.833843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.598131</td>\n",
              "      <td>0.471867</td>\n",
              "      <td>0.833481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.616822</td>\n",
              "      <td>0.482981</td>\n",
              "      <td>0.827727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83362be8-2c02-4abe-9313-d5b70701481b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83362be8-2c02-4abe-9313-d5b70701481b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83362be8-2c02-4abe-9313-d5b70701481b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
        "\n",
        "glass_train_df = pd.read_csv(filepath + \"glass_train.csv\")\n",
        "\n",
        "glass_test_df = pd.read_csv(filepath + \"glass_test.csv\")\n",
        "\n",
        "knn_model = kNN()\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "knn_model.fit(glass_train_df)\n",
        "print(\"Training time: {0:.2f} s.\".format(time.perf_counter()-t0))\n",
        "\n",
        "test_labels = glass_test_df[\"CLASS\"]\n",
        "\n",
        "k_values = [1,3,5,7,9]\n",
        "results = np.empty((len(k_values),3))\n",
        "\n",
        "#print(test_labels)\n",
        "\n",
        "for i in range(len(k_values)):\n",
        "    t0 = time.perf_counter()\n",
        "    predictions = knn_model.predict(glass_test_df, k=k_values[i])\n",
        "    print(\"Testing time (k={0}): {1:.2f} s.\".format(k_values[i],time.perf_counter()-t0))\n",
        "    results[i] = [accuracy(predictions, test_labels), brier_score(predictions, test_labels),\n",
        "                  auc(predictions, test_labels)] # Assuming that you have defined auc - remove otherwise\n",
        "\n",
        "results = pd.DataFrame(results,index=k_values,columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
        "\n",
        "print()\n",
        "display(\"results\",results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATYkSUjx8Aww",
        "outputId": "db229954-c19f-4844-ede9-80c067db1e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set (k=1): 1.0000\n",
            "AUC on training set (k=1): 1.0000\n",
            "Brier score on training set (k=1): 0.0000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_labels = glass_train_df[\"CLASS\"]\n",
        "predictions = knn_model.predict(glass_train_df,k=1)\n",
        "print(\"Accuracy on training set (k=1): {0:.4f}\".format(accuracy(predictions,train_labels)))\n",
        "print(\"AUC on training set (k=1): {0:.4f}\".format(auc(predictions,train_labels)))\n",
        "print(\"Brier score on training set (k=1): {0:.4f}\".format(brier_score(predictions,train_labels)))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HlUIb5A8Awx"
      },
      "source": [
        "## 2. Define the class NaiveBayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuRdWB_t8Awx"
      },
      "outputs": [],
      "source": [
        "# Define the class NaiveBayes with three functions __init__, fit and predict (after the comments):\n",
        "\n",
        "# Input to __init__:\n",
        "# self - the object itself\n",
        "#\n",
        "# Output from __init__:\n",
        "# <nothing>\n",
        "#\n",
        "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
        "# column_filter, binning, labels, class_priors, feature_class_value_counts, feature_class_counts\n",
        "\n",
        "class NaiveBayes :\n",
        "\n",
        "    def __init__(self):\n",
        "        self.column_filter = None\n",
        "        self.binning = None\n",
        "        self.labels = None\n",
        "        self.class_priors = None\n",
        "        self.feature_class_value_counts = None\n",
        "        self.feature_class_counts = None\n",
        "\n",
        "# Input to fit:\n",
        "# self    - the object itself\n",
        "# df      - a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
        "# nobins  - no. of bins (default = 10)\n",
        "# bintype - either \"equal-width\" (default) or \"equal-size\"\n",
        "#\n",
        "# Output from fit:\n",
        "# <nothing>\n",
        "#\n",
        "# The result of applying this function should be:\n",
        "#\n",
        "# self.column_filter              - a column filter (see Assignment 1) from df\n",
        "# self.binning                    - a discretization mapping (see Assignment 1) from df\n",
        "# self.class_priors               - a mapping (dictionary) from the labels (categories) of the \"CLASS\" column of df,\n",
        "#                                   to the relative frequencies of the labels\n",
        "# self.labels                     - a list of the categories (class labels) of the \"CLASS\" column of df\n",
        "# self.feature_class_value_counts - a mapping from the feature (column name) to the number of\n",
        "#                                   training instances with a specific combination of (non-missing, categorical)\n",
        "#                                   value for the feature and class label\n",
        "# self.feature_class_counts       - a mapping from the feature (column name) to the number of\n",
        "#                                   training instances with a specific class label and some (non-missing, categorical)\n",
        "#                                   value for the feature\n",
        "#\n",
        "\n",
        "    # for each column, count\n",
        "    def class_value_counts(self,df):\n",
        "        dfcpy = df.copy()\n",
        "\n",
        "        self.unique_values = {} #dictionary mapping colname with the unique values in the columns\n",
        "        for colname in dfcpy.columns:\n",
        "            test = dfcpy[colname].unique()\n",
        "            self.unique_values[colname] = test\n",
        "\n",
        "        #dictionnary mapping the column name to a certain combi of value and class\n",
        "        mapping = {}\n",
        "\n",
        "        #dictionary mapping colname with the unique values in the columns\n",
        "        # loop through every column\n",
        "        for colname in dfcpy.columns:\n",
        "            if colname == \"CLASS\" or colname == \"ID\":\n",
        "                continue\n",
        "\n",
        "            # group by column values and class\n",
        "            mapping_in = {}\n",
        "            g = dfcpy.groupby([colname,'CLASS'])\n",
        "\n",
        "            # occurence of the same class and same value of the column\n",
        "            df_count = g.size()\n",
        "\n",
        "            #loop through the unique values of each column\n",
        "            for unique in self.unique_values[colname]:\n",
        "\n",
        "                # loop through the labels\n",
        "                for label in self.labels:\n",
        "                    try:\n",
        "                        # get_group returns a dataframe if no counts for combination return a key error\n",
        "                        mapping_in[(unique,label)] = len(g.get_group((unique,label)))\n",
        "                    except KeyError:\n",
        "                        mapping_in[(unique,label)] = 0\n",
        "                mapping[colname] = mapping_in\n",
        "\n",
        "        return mapping\n",
        "\n",
        "    # count occurences of class per column\n",
        "    def class_counts(self, df):\n",
        "        dfcpy = df.copy()\n",
        "\n",
        "        mapping = {}\n",
        "        mapping_in = {}\n",
        "\n",
        "        # loop through every column\n",
        "        for colname in dfcpy.columns:\n",
        "            if colname == \"CLASS\" or colname == \"ID\":\n",
        "                continue\n",
        "\n",
        "            # group by class\n",
        "            g = dfcpy.groupby(['CLASS'])\n",
        "\n",
        "            # loop through the labels\n",
        "            for label in self.labels:\n",
        "                #create the inner dictionary\n",
        "                mapping_in[label] = len(g.get_group((label)))\n",
        "            #create the outer dictionary\n",
        "            mapping[colname] = mapping_in\n",
        "\n",
        "        return mapping\n",
        "\n",
        "\n",
        "    def fit(self, df, nobins = 10 , bintype = \"equal-width\"):\n",
        "        dfcpy = df.copy()\n",
        "\n",
        "        #filter\n",
        "        df_filtered, col_filter = create_column_filter(dfcpy)\n",
        "        self.column_filter = col_filter\n",
        "\n",
        "        #create binnings\n",
        "        #self.train_data, binning = create_bins(dfcpy, nobins = 10, bintype = \"equal-width\")\n",
        "        self.train_data, binning = create_bins(df_filtered, nobins, bintype)\n",
        "        self.binning = binning\n",
        "        #self.train_data = self.train_data.drop(['CLASS','ID'], axis=1)\n",
        "\n",
        "        #create a list of the class labels of the \"CLASS\" column\n",
        "        self.categories = dfcpy['CLASS'].astype('category')\n",
        "        self.labels = sorted(self.categories.unique())\n",
        "\n",
        "        # create the mapping from the labels of the \"CLASS\"\n",
        "        # to the relative frequencies of the labels\n",
        "        freq = dfcpy['CLASS'].value_counts() # returns a dataframe of the labels in 'CLASS' associated with their frequency\n",
        "        mapping_freq = {}\n",
        "        for i in self.labels:\n",
        "           mapping_freq[i] = freq[i]/np.sum(freq)\n",
        "        self.class_priors = mapping_freq\n",
        "\n",
        "        #create a mapping from the column name to the number of\n",
        "        #training instances with a specific combination of (value, class)\n",
        "        # colname -> {(class,value)->nr of occurence ,...}\n",
        "        # Mg -> {(7,0)->15 ,...}\n",
        "        self.feature_class_value_counts = self.class_value_counts(self.train_data)\n",
        "\n",
        "        #create a mapping from the column name to the number of\n",
        "        #training instances with a specific class label\n",
        "        # colname -> {class->nr of occurence ,...}\n",
        "        # Mg -> {7->15 ,...}\n",
        "        self.feature_class_counts = self.class_counts(self.train_data)\n",
        "\n",
        "# Input to predict:\n",
        "# self - the object itself\n",
        "# df   - a dataframe\n",
        "#\n",
        "# Output from predict:\n",
        "# predictions - a dataframe with class labels as column names and the rows corresponding to\n",
        "#               predictions with estimated class probabilities for each row in df, where the class probabilities\n",
        "#               are estimated by the naive approximation of Bayes rule (see lecture slides)\n",
        "#\n",
        "# Hint 1: First apply the column filter and discretization\n",
        "#\n",
        "# Hint 2: Iterating over either columns or rows, and for each possible class label, calculate the relative\n",
        "#         frequency of the observed feature value given the class (using feature_class_value_counts and\n",
        "#         feature_class_counts)\n",
        "#\n",
        "# Hint 3: Calculate the non-normalized estimated class probabilities by multiplying the class priors to the\n",
        "#         product of the relative frequencies\n",
        "#\n",
        "# Hint 4: Normalize the probabilities by dividing by the sum of the non-normalized probabilities; in case\n",
        "#         this sum is zero, then set the probabilities to the class priors\n",
        "#\n",
        "# Hint 5: To clarify the assignment text a little: self.feature_class_value_counts should be a mapping from\n",
        "#         a column name (a specific feature) to another mapping, which given a class label and a value for\n",
        "#         the feature, returns the number of training instances which have included this combination,\n",
        "#         i.e., the number of training instances with both the specific class label and this value on the feature.\n",
        "#\n",
        "# Hint 6: As an additional hint, you may take a look at the slides from the NumPy and pandas lecture, to see how you\n",
        "#         may use \"groupby\" in combination with \"size\" to get the counts for combinations of values from two columns.\n",
        "\n",
        "    def predict(self, df):\n",
        "        dfcpy = df.copy()\n",
        "\n",
        "        # apply col filter and binning\n",
        "        df_filtered = apply_column_filter(dfcpy, self.column_filter)\n",
        "        df_binned = apply_bins(df_filtered, self.binning)\n",
        "        self.test_data = df_binned.drop(['CLASS','ID'], axis=1)\n",
        "\n",
        "        # hint 2 : likelihood\n",
        "        likelihood_in={}\n",
        "        for colname in self.test_data.columns:\n",
        "            likelihood={}\n",
        "            for pair in list(self.feature_class_value_counts[colname].keys()):\n",
        "\n",
        "                class_label = pair[1]\n",
        "\n",
        "                # nr of (value,class) occurences in col\n",
        "                pair_occurences = self.feature_class_value_counts[colname][pair]\n",
        "                # nr of class occurences in col\n",
        "                class_occurences = self.feature_class_counts[colname][class_label]\n",
        "\n",
        "                # save relative frequency of observed feature value given the class\n",
        "                likelihood_in[pair] = pair_occurences/class_occurences\n",
        "\n",
        "            likelihood[colname] = likelihood_in\n",
        "            #print(likelihood)\n",
        "\n",
        "        #hint3\n",
        "        # Hint 3: Calculate the non-normalized estimated class probabilities by multiplying the class priors to the\n",
        "        #         product of the relative frequencies\n",
        "        probs = np.zeros((len(self.test_data), len(self.labels)))\n",
        "        # for each row\n",
        "        for id_row, row in self.test_data.iterrows():\n",
        "            for l, label in enumerate(self.labels):\n",
        "\n",
        "            # for each class label 1,2,3,5,6,7\n",
        "\n",
        "                mult = 1\n",
        "                # for each column RI, ...\n",
        "                for colname in self.test_data.columns:\n",
        "\n",
        "                    value = self.test_data.loc[id_row, colname] # get testdata value\n",
        "                    #print(value)\n",
        "                    try:\n",
        "                        mult *= likelihood[colname][(value, label)] # multiply relative freq of value,label\n",
        "                    except KeyError:\n",
        "                        mult *= 0\n",
        "\n",
        "                probs[id_row, l] = mult * self.class_priors[label]\n",
        "\n",
        "        # hint4\n",
        "        # prior probability (values) as list\n",
        "        priors = list(self.class_priors.values())\n",
        "\n",
        "        # for each row\n",
        "        for row in range(probs.shape[0]):\n",
        "            # calculate sum of row\n",
        "            row_sum = np.sum(probs[row,:])\n",
        "\n",
        "            # if sum of row nonzero, divide row with sum elemwise\n",
        "            if row_sum != 0:\n",
        "                probs[row,:] /= row_sum\n",
        "\n",
        "            # if sum of row is ZERO, set probs to priors\n",
        "            else:\n",
        "                probs[row,:] = priors\n",
        "\n",
        "        probs_df = pd.DataFrame(probs,columns=self.labels)\n",
        "\n",
        "        return probs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "vblKLLc58Awx",
        "outputId": "b894f1df-611a-4f86-ed8c-e25440c5e47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (3, 'equal-width'): 0.15 s.\n",
            "Testing time (3, 'equal-width'): 0.14 s.\n",
            "Training time (3, 'equal-size'): 0.16 s.\n",
            "Testing time (3, 'equal-size'): 0.13 s.\n",
            "Training time (5, 'equal-width'): 0.15 s.\n",
            "Testing time (5, 'equal-width'): 0.12 s.\n",
            "Training time (5, 'equal-size'): 0.16 s.\n",
            "Testing time (5, 'equal-size'): 0.12 s.\n",
            "Training time (10, 'equal-width'): 0.23 s.\n",
            "Testing time (10, 'equal-width'): 0.15 s.\n",
            "Training time (10, 'equal-size'): 0.21 s.\n",
            "Testing time (10, 'equal-size'): 0.12 s.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'results'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Accuracy  Brier score  AUC\n",
              "3  equal-width  0.392523     0.719364  0.5\n",
              "   equal-size   0.392523     0.719364  0.5\n",
              "5  equal-width  0.392523     0.719364  0.5\n",
              "   equal-size   0.392523     0.719364  0.5\n",
              "10 equal-width  0.392523     0.719364  0.5\n",
              "   equal-size   0.392523     0.719364  0.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a05cf50f-ed02-4c52-ae1c-d17640ef1a80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Brier score</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>equal-width</th>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equal-size</th>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
              "      <th>equal-width</th>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equal-size</th>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
              "      <th>equal-width</th>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equal-size</th>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a05cf50f-ed02-4c52-ae1c-d17640ef1a80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a05cf50f-ed02-4c52-ae1c-d17640ef1a80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a05cf50f-ed02-4c52-ae1c-d17640ef1a80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
        "\n",
        "glass_train_df = pd.read_csv(filepath+\"glass_train.csv\")\n",
        "\n",
        "glass_test_df = pd.read_csv(filepath+\"glass_test.csv\")\n",
        "\n",
        "nb_model = NaiveBayes()\n",
        "\n",
        "test_labels = glass_test_df[\"CLASS\"]\n",
        "\n",
        "nobins_values = [3,5,10]\n",
        "bintype_values = [\"equal-width\",\"equal-size\"]\n",
        "parameters = [(nobins,bintype) for nobins in nobins_values for bintype in bintype_values]\n",
        "\n",
        "results = np.empty((len(parameters),3))\n",
        "\n",
        "for i in range(len(parameters)):\n",
        "    t0 = time.perf_counter()\n",
        "    nb_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1])\n",
        "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
        "    t0 = time.perf_counter()\n",
        "    predictions = nb_model.predict(glass_test_df)\n",
        "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
        "    results[i] = [accuracy(predictions, test_labels),brier_score(predictions,test_labels),\n",
        "                   auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
        "\n",
        "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values]),\n",
        "                        columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
        "\n",
        "print()\n",
        "display(\"results\",results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evlzuoUf8Awx",
        "outputId": "e5357e70-b56b-4b73-a6f6-84dc92d5a669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 0.3178\n",
            "AUC on training set: 0.5000\n",
            "Brier score on training set: 0.7658\n"
          ]
        }
      ],
      "source": [
        "train_labels = glass_train_df[\"CLASS\"]\n",
        "nb_model.fit(glass_train_df)\n",
        "predictions = nb_model.predict(glass_train_df)\n",
        "print(\"Accuracy on training set: {0:.4f}\".format(accuracy(predictions,train_labels)))\n",
        "print(\"AUC on training set: {0:.4f}\".format(auc(predictions,train_labels)))\n",
        "print(\"Brier score on training set: {0:.4f}\".format(brier_score(predictions,train_labels)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jzZWP5TG8Awv"
      ]
    },
    "kernelspec": {
      "display_name": "project3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c414820bddd2bda2eb7b5fd6353b1c896ecc6ee1d0230192059569cdab477ee1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}